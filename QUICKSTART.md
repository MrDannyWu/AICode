# å¿«é€Ÿå¼€å§‹æŒ‡å—

## 5åˆ†é’Ÿå¿«é€Ÿä¸Šæ‰‹

### 1. å®‰è£…ä¾èµ–ï¼ˆ1åˆ†é’Ÿï¼‰

```bash
pip install -r requirements.txt
```

### 2. åŸºæœ¬ä½¿ç”¨ï¼ˆ2åˆ†é’Ÿï¼‰

#### æœ€ç®€å•çš„æ–¹å¼ - ç›´æ¥è¿è¡Œè„šæœ¬

```bash
python fund_scraper.py
```

è¿™å°†æŠ“å–3ä¸ªç¤ºä¾‹åŸºé‡‘å¹¶ä¿å­˜åˆ° `output/` ç›®å½•ã€‚

#### ä½¿ç”¨å‘½ä»¤è¡Œå·¥å…·

```bash
# æŠ“å–å•ä¸ªåŸºé‡‘
python scrape_funds.py -c 110022

# æŠ“å–å¤šä¸ªåŸºé‡‘å¹¶ä¿å­˜ä¸ºCSV
python scrape_funds.py -c 110022 161725 163402 -o funds.csv

# ä»æ–‡ä»¶è¯»å–åŸºé‡‘åˆ—è¡¨
python scrape_funds.py -f funds_example.txt -o funds.json
```

### 3. åœ¨Pythonä¸­ä½¿ç”¨ï¼ˆ2åˆ†é’Ÿï¼‰

```python
from fund_scraper import FundScraper

# åˆ›å»ºçˆ¬è™«
scraper = FundScraper()

# æŠ“å–å•ä¸ªåŸºé‡‘
fund = scraper.scrape_fund('110022')
print(fund)

# æŠ“å–å¤šä¸ªåŸºé‡‘
funds = scraper.scrape_multiple_funds(['110022', '161725', '163402'])

# è½¬æ¢ä¸ºDataFrame
df = scraper.to_dataframe(funds)
print(df)

# ä¿å­˜æ•°æ®
scraper.save_to_csv(df, 'funds.csv')
scraper.save_to_json(funds, 'funds.json')
```

### 4. è·å–å†å²æ•°æ®ï¼ˆæ–°åŠŸèƒ½ï¼ï¼‰

```python
from fund_scraper import FundScraper

scraper = FundScraper()

# è·å–å•ä¸ªåŸºé‡‘æœ€è¿‘30å¤©çš„å†å²æ•°æ®
history = scraper.get_fund_history('110022', days=30)
print(f"è·å– {len(history)} æ¡å†å²è®°å½•")

# æ‰¹é‡è·å–å¤šä¸ªåŸºé‡‘çš„å†å²æ•°æ®
history_data = scraper.get_multiple_funds_history(['110022', '161725'], days=30)

# ä¿å­˜ä¸ºCSVæˆ–JSON
scraper.save_history_to_csv(history_data, 'history.csv')
scraper.save_history_to_json(history_data, 'history.json')
```

æˆ–ä½¿ç”¨å‘½ä»¤è¡Œï¼š

```bash
# è·å–æœ€è¿‘30å¤©çš„å†å²æ•°æ®
python scrape_funds.py -c 110022 --history 30

# ä¿å­˜ä¸ºCSV
python scrape_funds.py -c 110022 --history 30 -o fund_history.csv

# æ‰¹é‡è·å–å¹¶ä¿å­˜
python scrape_funds.py -f funds.txt --history 30 -o history.csv
```

## å¸¸ç”¨å‘½ä»¤

| å‘½ä»¤ | è¯´æ˜ |
|------|------|
| `python scrape_funds.py -h` | æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯ |
| `python scrape_funds.py -c 110022` | æŠ“å–ä»£ç ä¸º110022çš„åŸºé‡‘ |
| `python scrape_funds.py -c 110022 -d` | è·å–è¯¦ç»†ä¿¡æ¯ |
| `python scrape_funds.py -c 110022 -o fund.csv` | ä¿å­˜ä¸ºCSV |
| `python scrape_funds.py -f funds.txt` | ä»æ–‡ä»¶è¯»å–åŸºé‡‘åˆ—è¡¨ |
| `python scrape_funds.py -c 110022 -l 1.0` | è®¾ç½®1ç§’å»¶è¿Ÿ |
| `python scrape_funds.py -c 110022 --history 30` | è·å–æœ€è¿‘30å¤©å†å²æ•°æ® |
| `python scrape_funds.py -f funds.txt --history 90 -o history.csv` | æ‰¹é‡è·å–å†å²æ•°æ® |
| `python scrape_funds.py` | è¿›å…¥äº¤äº’æ¨¡å¼ |

## å¸¸è§åŸºé‡‘ä»£ç 

- **110022** - æ˜“æ–¹è¾¾æ¶ˆè´¹è¡Œä¸š
- **161725** - æ‹›å•†ä¸­è¯ç™½é…’
- **163402** - å…´å…¨è¶‹åŠ¿æŠ•èµ„
- **519674** - åå¤å›æŠ¥æ··åˆ
- **470018** - æ±‡æ·»å¯Œå‡è¡¡å¢é•¿

åœ¨ [å¤©å¤©åŸºé‡‘ç½‘](https://www.1234567.com.cn/) æœç´¢åŸºé‡‘åç§°å¯è·å¾—æ­£ç¡®çš„ä»£ç ã€‚

## æ•°æ®è¾“å‡ºç¤ºä¾‹

### CSVæ ¼å¼

```
fund_code,fund_name,unit_net_value,accumulated_net_value,daily_growth_rate,update_date
110022,æ˜“æ–¹è¾¾æ¶ˆè´¹è¡Œä¸š,5.8234,5.8234,0.12,2024-01-15
161725,æ‹›å•†ä¸­è¯ç™½é…’,2.1567,2.1567,-0.45,2024-01-15
```

### JSONæ ¼å¼

```json
[
  {
    "fund_code": "110022",
    "fund_name": "æ˜“æ–¹è¾¾æ¶ˆè´¹è¡Œä¸š",
    "unit_net_value": 5.8234,
    "accumulated_net_value": 5.8234,
    "daily_growth_rate": 0.12,
    "update_date": "2024-01-15"
  }
]
```

## é‡åˆ°é—®é¢˜ï¼Ÿ

### é—®é¢˜1ï¼š`ModuleNotFoundError: No module named 'requests'`

**è§£å†³æ–¹æ¡ˆï¼š** å®‰è£…ä¾èµ–
```bash
pip install -r requirements.txt
```

### é—®é¢˜2ï¼šæ— æ³•è·å–æ•°æ®æˆ–æ˜¾ç¤ºé”™è¯¯

**è§£å†³æ–¹æ¡ˆï¼š** 
1. æ£€æŸ¥ç½‘ç»œè¿æ¥
2. éªŒè¯åŸºé‡‘ä»£ç æ˜¯å¦æ­£ç¡®ï¼ˆåº”è¯¥æ˜¯6ä½æ•°å­—ï¼‰
3. å¢åŠ è¯·æ±‚å»¶è¿Ÿï¼š`python scrape_funds.py -c 110022 -l 2.0`
4. ç­‰å¾…å‡ åˆ†é’Ÿåé‡è¯•

### é—®é¢˜3ï¼šçˆ¬å–é€Ÿåº¦å¤ªæ…¢

**è§£å†³æ–¹æ¡ˆï¼š** è¿™æ˜¯æ•…æ„çš„ï¼ˆåçˆ¬è™«å¯¹ç­–ï¼‰ã€‚å»ºè®®ï¼š
- ä¸€æ¬¡æ€§æŠ“å–æ‰€æœ‰éœ€è¦çš„åŸºé‡‘
- ä½¿ç”¨ `-f` å‚æ•°ä»æ–‡ä»¶è¯»å–åŸºé‡‘åˆ—è¡¨
- ä¸è¦é¢‘ç¹è¿è¡Œè„šæœ¬

## æ›´å¤šç¤ºä¾‹

æŸ¥çœ‹ `example_usage.py` æ–‡ä»¶äº†è§£æ›´å¤šé«˜çº§ç”¨æ³•ï¼š

```bash
python example_usage.py
```

## è¯¦ç»†æ–‡æ¡£

å®Œæ•´æ–‡æ¡£è¯·å‚è€ƒ `README.md` æ–‡ä»¶ã€‚

---

å‡†å¤‡å¥½äº†ï¼Ÿå¼€å§‹æŠ“å–åŸºé‡‘æ•°æ®å§ï¼ ğŸš€
